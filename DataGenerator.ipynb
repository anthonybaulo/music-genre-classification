{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing the DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "    '''Generates .npy files for Conv2D'''\n",
    "    def __init__(self, data_dir, batch_size=32, dim=(128,640), \n",
    "                 n_channels=1, shuffle=True):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_dir : str\n",
    "            Path to data split (training, validation, or test)\n",
    "        batch_size : int\n",
    "            Number of files to return at a time\n",
    "        dim : tuple\n",
    "            Dimension of arrays to read in\n",
    "        n_channels : int\n",
    "            Number of color channels for image array\n",
    "        shuffle : bool\n",
    "            Shuffle indices between epochs\n",
    "        '''\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.label_dict = self.__get_label_dict()\n",
    "        self.files = self.__get_files()\n",
    "        self.n_classes = len(self.label_dict)   # Number of sub dirs\n",
    "        self.on_epoch_end()                     # populates self.indexes\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the number of batches per epoch'''\n",
    "        return int(np.floor(len(self.files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generate one batch of data'''\n",
    "        # Generate indexes of the batch\n",
    "        idxs = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        file_list = self.files[idxs]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(file_list)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        '''Updates indexes after each epoch'''\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes) # Shuffles in place\n",
    "            \n",
    "    def __get_files(self):\n",
    "        '''Get all files from subdirectories of data_dir'''\n",
    "        subdirs = sorted(os.listdir(self.data_dir))\n",
    "        all_files = []\n",
    "\n",
    "        for subdir in subdirs:\n",
    "            full_dir = os.path.join(self.data_dir, subdir)\n",
    "            files = os.listdir(full_dir)\n",
    "            for file in files:\n",
    "                all_files.append(os.path.join(subdir, file))\n",
    "\n",
    "        return np.array(all_files)\n",
    "\n",
    "    def __get_label_dict(self):\n",
    "        '''\n",
    "        Create dict of labels from sub directories\n",
    "        {Genre : int}\n",
    "        '''\n",
    "        subdirs = sorted(os.listdir(self.data_dir))\n",
    "        labels = np.arange(len(subdirs))\n",
    "        return {k:v for k,v in zip(subdirs, labels)}\n",
    "    \n",
    "    def __data_generation(self, file_list):\n",
    "        '''\n",
    "        Generates data containing batch_size samples\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_list : list or np.array\n",
    "            List of files to retrieve/process/load\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X : (n_samples, *dim, n_channels)\n",
    "        \n",
    "        '''  \n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        for i, file in enumerate(file_list):\n",
    "            npy = np.load(os.path.join(self.data_dir, file))\n",
    "            target = file.split('/')[0]\n",
    "            label = label_dict[target]\n",
    "            X[i,] = npy[:,:,None]   # Create extra dim for channel\n",
    "            y[i,] = label\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.n_classes, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = DataGenerator('data/test', batch_size=32, dim=(128,640), n_channels=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = datagen.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128, 640, 1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[1][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hip-Hop': 0, 'Instrumental': 1, 'Rock': 2}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = sorted(os.listdir(filepath))\n",
    "labels = np.arange(len(subdirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hip-Hop': 0, 'Instrumental': 1, 'Rock': 2}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v for k,v in zip(subdirs, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'Rock': 0,\n",
    "    'Instrumental': 1,    \n",
    "    'Hip-Hop': 2,\n",
    "    'Folk': 3,\n",
    "    'International': 4,            \n",
    "    'Electronic': 5,\n",
    "    'Experimental': 6,   \n",
    "    'Pop': 7 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of filenames in a directory\n",
    "\n",
    "filepath = 'data/test'\n",
    "def __get_files(filepath):\n",
    "    subdirs = os.listdir(filepath)\n",
    "    all_files = []\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        full_dir = os.path.join(filepath, subdir)\n",
    "        files = os.listdir(full_dir)\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(subdir, file))\n",
    "\n",
    "    return np.array(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = __get_files(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hip-Hop/132117.npy', 'Hip-Hop/110771.npy', 'Hip-Hop/140626.npy'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = [0,33,99]\n",
    "all_files[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "npy = np.load(os.path.join(filepath, all_files[0]))\n",
    "shape = npy.shape\n",
    "\n",
    "channels = 1\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __data_generation(all_files):\n",
    "    X = np.empty((batch_size, *shape, channels))\n",
    "    y = np.empty((batch_size), dtype=int)\n",
    "    \n",
    "    for i, file in enumerate(all_files[:batch_size]):\n",
    "        npy = np.load(os.path.join(filepath, file))\n",
    "        target = file.split('/')[0]\n",
    "        label = label_dict[target]\n",
    "        X[i,] = npy[:,:,None]\n",
    "        y[i,] = label\n",
    "    \n",
    "    return X, y\n",
    "# to_categorical(y, num_classes=n_classes, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = __data_generation(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(y, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((batch_size, *shape, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hip-Hop'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
