{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from src.datagen import DataGenerator\n",
    "from src.utils import get_ytrue_ypred_targets, save_confusion_matrix, save_summary_plots\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Dense, Dropout, \\\n",
    "                                    Activation, MaxPooling2D, Flatten, \\\n",
    "                                    BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (9, 9), \n",
    "                    input_shape = (128, 640, 1), \n",
    "                    padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units = 256, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units = 128, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units = 64, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units = 2, activation = 'softmax'))\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_cb_list(name):\n",
    "    earlystop_callback = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                                       patience=10, min_delta=0.005, verbose=1,   \n",
    "                                       restore_best_weights=True)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(f'./models/{name}_weights_best_val_loss.h5', \n",
    "                                          monitor='val_loss', mode='min',\n",
    "                                          save_best_only=True, verbose=1)\n",
    "\n",
    "    reducelr_callback = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.8, \n",
    "                                          patience=2, min_delta=0.005, verbose=1)\n",
    "\n",
    "    callbacks_list = [checkpoint_callback, reducelr_callback, earlystop_callback]\n",
    "\n",
    "    return callbacks_list\n",
    "\n",
    "\n",
    "def get_datagens(include=['Rock', 'Hip-Hop'], \n",
    "                 splits=['training', 'validation', 'test'], \n",
    "                 bs=[64,16,1]):\n",
    "    datagens = []\n",
    "    test = False\n",
    "\n",
    "    for split, bs in zip(splits, bs):\n",
    "        if 'test' in split:\n",
    "            test = True\n",
    "\n",
    "        datagen = DataGenerator('./data/'+split, include=include, \n",
    "                                batch_size=bs, dim=(128,640), \n",
    "                                n_channels=1, test=test)\n",
    "\n",
    "        datagens.append(datagen)\n",
    "    \n",
    "    return tuple(datagens)\n",
    "\n",
    "\n",
    "def main(name='model3'):\n",
    "    # Build model\n",
    "    model = build_model()\n",
    "\n",
    "    # Get callbacks\n",
    "    cbs = get_cb_list(name)\n",
    "\n",
    "    # Get datagens\n",
    "    train_dg, valid_dg, test_dg = get_datagens(include=['Rock', 'Hip-Hop'], \n",
    "                                               splits=['training', 'validation', 'test'], \n",
    "                                               bs=[64,16,1])\n",
    "\n",
    "    # Train\n",
    "    history = model.fit_generator(generator=train_dg, epochs=100,\n",
    "                                  validation_data=valid_dg, verbose=0, \n",
    "                                  callbacks=cbs)\n",
    "\n",
    "    # Save\n",
    "    model.save(f'./models/{name}_arch_and_weights.h5')\n",
    "    save_summary_plots(history, fpath=f'./images/{name}_summary.png')\n",
    "    y_true, y_pred, target_names = get_ytrue_ypred_targets(model, test_dg)\n",
    "    save_confusion_matrix(y_true, y_pred, target_names, fpath=f'./images/{name}_cm.png')\n",
    "    \n",
    "    # Print\n",
    "    acc = model.evaluate_generator(test_dg)[1]\n",
    "    print('Accuracy on test: {:.2f}%\\n'.format(acc*100))\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
