{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_DIR = Path('../data/fma_metadata')\n",
    "AUDIO_DIR = Path('../data/fma_small')\n",
    "CONVERTED_DIR = Path('../data/converted/rock_hiphop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/mdeff/fma/blob/master/utils.py\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import utils\n",
    "    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    >>> utils.get_audio_path(AUDIO_DIR, 2)\n",
    "    '../data/fma_small/000/000002.mp3'\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
    "\n",
    "\n",
    "def get_tids_from_directory(audio_dir):\n",
    "    \"\"\"Get track IDs from the mp3s in a directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_dir : str\n",
    "        Path to the directory where the audio files are stored.\n",
    "    Returns\n",
    "    -------\n",
    "        A list of track IDs.\n",
    "    \"\"\"\n",
    "    tids = []\n",
    "    for _, dirnames, files in os.walk(audio_dir):\n",
    "        if dirnames == []:\n",
    "            tids.extend(int(file[:-4]) for file in files)\n",
    "    return tids\n",
    "\n",
    "\n",
    "# Based on https://github.com/priya-dwivedi/Music_Genre_Classification/\n",
    "\n",
    "def create_spectrogram(track_id):\n",
    "    filename = get_audio_path(AUDIO_DIR, track_id)\n",
    "    y, sr = librosa.load(filename)\n",
    "    spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=512)\n",
    "    spect = librosa.power_to_db(spect, ref=np.max)\n",
    "    return spect.T\n",
    "\n",
    "def plot_spect(track_id):\n",
    "    spect = create_spectrogram(track_id)\n",
    "    print(spect.shape)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spect.T, y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "    \n",
    "def create_array(df, genre_dict):\n",
    "    genres = []\n",
    "    X_spect = np.empty((0, 640, 128))\n",
    "    total = len(df)\n",
    "    count = 0\n",
    "    #Code skips records in case of errors\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            count += 1\n",
    "            track_id = int(row['track_id'])\n",
    "            genre = str(row[('track', 'genre_top')])\n",
    "            spect = create_spectrogram(track_id)\n",
    "\n",
    "            # Normalize for small shape differences\n",
    "            spect = spect[:640, :]\n",
    "            X_spect = np.append(X_spect, [spect], axis=0)\n",
    "            genres.append(genre_dict[genre])\n",
    "            if count%100 == 0:\n",
    "                print(\"Processed {} of {}\"\n",
    "                      .format(count, total, track_id))\n",
    "        except:\n",
    "            print(\"Couldn't process: {} of {} - track {}\"\n",
    "                  .format(count, total, track_id))\n",
    "            continue\n",
    "    y_arr = np.array(genres)\n",
    "    return X_spect, y_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(META_DIR/'tracks.csv', index_col=0, header=[0, 1]) \n",
    "\n",
    "# Keep necessary columns\n",
    "keep_cols = [('set', 'split'), ('set', 'subset'),('track', 'genre_top')]\n",
    "df_all = tracks[keep_cols]\n",
    "\n",
    "# Use small dataset\n",
    "df_all = df_all[df_all[('set', 'subset')] == 'small']\n",
    "\n",
    "# Move index to track_id column\n",
    "df_all['track_id'] = df_all.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim down to 2 genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock = df_all[('track', 'genre_top')] == 'Rock'\n",
    "hiphop = df_all[('track', 'genre_top')] == 'Hip-Hop'\n",
    "mask = rock | hiphop\n",
    "\n",
    "two_genre = df_all[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {'Rock': 0, 'Hip-Hop': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, validation and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = two_genre[two_genre[('set', 'split')] == 'training'  ]\n",
    "df_valid = two_genre[two_genre[('set', 'split')] == 'validation']\n",
    "df_test  = two_genre[two_genre[('set', 'split')] == 'test'      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spectrogram Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    p = np.random.permutation(len(X))\n",
    "    return X[p], y[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save(dfs, fnames, genre_dict):\n",
    "    for df, fname in zip(dfs, fnames):\n",
    "        X, y = create_array(df, genre_dict)\n",
    "        X_shuf, y_shuf = shuffle(X, y)\n",
    "    \n",
    "        np.savez(CONVERTED_DIR/fname, X=X_shuf, y=y_shuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_test, df_valid, df_train]\n",
    "fnames = ['test_arr', 'valid_arr', 'train_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_save(dfs, fnames, genre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
